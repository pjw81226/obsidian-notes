---
title: Kafka 토픽 컷오버(Cutover)로 심볼 키 기반 파티션 확장 문제 해결
date: 2026-01-06
tags:
  - kafka
  - flink
  - binance
  - partitioning
  - 운영
---

## 한 줄 요약
**컷오버(Cutover)**는 “기존 토픽(v1)에서 새 토픽(v2)으로 생산/소비를 전환하는 운영 절차”이고, 심볼을 Kafka key로 쓰는 구조에서 **파티션 확장 시 순서 보장이 깨질 수 있는 문제**를 안전하게 피하기 위한 방법이다.

---

## 컷오버(Cutover)란?
운영에서 말하는 컷오버는 보통 아래처럼 정의한다.

- 기존 시스템(또는 리소스)에서 새 시스템(또는 리소스)으로 **트래픽을 전환(switch over)** 하는 행위
- 이 프로젝트 문맥에서는:
  - **기존 Kafka 토픽(v1)** 에 쓰던 Producer/Flink를
  - **새 Kafka 토픽(v2)** 로 **환경변수만 바꿔 재시작**해서 전환하는 것

즉, “토픽을 v2로 갈아타는 스위칭 작업”이다.

---

## 어떤 문제가 있었나? (심볼 key + 파티션 확장)
현재 Producer는 Kafka 메시지 key에 **심볼(symbol)** 을 넣는다.

- 장점: **심볼별 순서 보장**(한 심볼은 한 파티션에서만 순서가 보장됨)
- 단점: 특정 심볼(예: BTCUSDT)이 매우 핫해지면 해당 파티션이 병목이 됨 → “파티션을 늘려서 확장하고 싶다”는 요구가 생김

하지만 Kafka의 중요한 사실:

- Kafka의 순서 보장은 “토픽 전체”가 아니라 **파티션 단위**다.
- key가 있을 때 파티션은 대략 **hash(key) % partitionCount** 방식으로 선택된다.

따라서 **토픽의 파티션 수를 늘리면(partitionCount 변경)**:

- 같은 심볼도 **다른 파티션으로 이동**할 수 있다.
- 그 결과, 같은 심볼의 이벤트가 시간에 따라 서로 다른 파티션에 섞여 들어가며
  **심볼별 순서 보장이 깨질 수 있다.**

정리하면:

> “심볼별 순서 보장”을 유지하려고 key=심볼로 묶어놨는데,  
> 파티션을 늘리는 순간 그 묶임이 깨질 수 있어서 운영 확장이 위험해진다.

---

## 해결 접근: “기존 토픽 증설” 대신 “새 토픽(v2) + 컷오버”
핵심 아이디어는 단순하다.

- **v1 토픽의 파티션 수를 바꾸지 않는다** (순서 보장 깨짐 리스크 회피)
- 대신,
  - **v2 토픽을 새로 만들고(더 많은 파티션)**,
  - 어느 시점부터는 Producer/Flink가 **v2만** 사용하도록 전환한다(= 컷오버)

이렇게 하면:

- v1은 v1대로 파티션 수가 고정 → v1 내부에서 키→파티션 매핑이 안정적
- v2도 v2대로 파티션 수가 고정 → v2 내부에서도 매핑이 안정적
- “파티션 수 변경으로 매핑이 흔들리는 문제”를 회피한다.

### 중요한 운영 포인트(순서 필수 조건)
컷오버 순간에 **v1과 v2에 동시에 쓰기 시작하면** (특히 같은 심볼)
소비 입장에선 “심볼의 스트림이 두 토픽에 분산”되어 순서가 다시 깨질 수 있다.

그래서 컷오버는 원칙적으로:

- **Producer 쓰기 중단 → v2로 전환 → 재시작**
- (필요 시) Flink도 동일하게 v2 소비로 전환

이 “짧은 중단/전환 구간”을 감수하는 대신 순서 보장을 지킨다.

---

## 이번 코드 변경이 무엇을 ‘가능하게’ 했나? (핵심: 환경변수 기반 스위칭)
이 프로젝트는 컷오버를 쉽게 하기 위해 “토픽명 하드코딩”을 없애고,
**환경변수로 토픽명을 주입**하도록 바꿨다.

### 1) Producer: RAW 토픽명을 환경변수로
- `RAW_TOPIC_KLINE`
- `RAW_TOPIC_AGGTRADE`
- `RAW_TOPIC_BOOKTICKER`

즉, Producer는 코드 변경 없이:
- v1 토픽을 쓰다가
- env를 바꿔 v2 토픽으로 전환 가능

### 2) Flink: RAW/Signal 토픽명을 환경변수로
- `RAW_TOPIC_*`
- `SIGNAL_TOPIC_VOLUME`
- `SIGNAL_TOPIC_MOMENTUM`

Flink도 동일하게 코드 변경 없이 토픽 전환 가능.

### 3) Flink: 시작 오프셋 모드 선택 가능
- `RAW_TOPIC_OFFSETS=earliest|latest`

컷오버 시 “v2 토픽의 기존 데이터를 처음부터 읽을지/지금부터 읽을지”를 운영자가 결정할 수 있다.

### 4) 토픽 생성도 운영자가 통제 가능
- `ENSURE_TOPICS=true|false`
- `RAW_TOPIC_PARTITIONS`, `SIGNAL_TOPIC_PARTITIONS`, `TOPIC_REPLICATION_FACTOR`

예를 들어 v2 토픽을 “더 많은 파티션”으로 만들고 싶으면:
- v2 토픽명을 env로 지정하고
- 파티션 수 env를 크게 잡고
- 토픽 생성 후 컷오버

같은 흐름이 가능해졌다.

---

## 컷오버 절차(권장)
아래는 “심볼별 순서 보장”을 지키는 전제에서 안전한 절차다.

1. (사전) v2 토픽명 결정  
   - 예: `binance.raw.kline.v2`, `binance.raw.aggtrade.v2`, `binance.raw.bookticker.v2`
2. (사전) v2 토픽 생성(파티션 수는 충분히 크게)  
3. **Producer 중지** (v1 토픽 쓰기 중단)
4. (필요 시) Flink 중지/정리  
   - v1 토픽 소비를 끝내고 v2로 전환 준비
5. 환경변수 변경  
   - Producer/Flink의 `RAW_TOPIC_*`, `SIGNAL_TOPIC_*` 를 v2로
6. **Producer 재시작** (이제 v2에만 write)
7. **Flink 재시작** (이제 v2에서 read → v2 signal로 write)
8. consumer는 signal 토픽을 v2로 바꾸었다면 동일하게 전환(또는 compose env로 주입)

---

## 한계/주의사항(정직하게)
- 컷오버는 “파티션 수 변경으로 인해 키 매핑이 흔들리는 문제”를 회피하는 방법이지,
  **핫 심볼 하나를 여러 파티션으로 쪼개면서도 ‘완전한 순서’를 지키는 문제**를 해결하진 못한다.
- 심볼별 순서가 절대적이면, 한 심볼은 결국 **한 파티션의 처리량 한계**를 가진다.
  (이건 Kafka 파티션 모델 자체의 특성)

---

## 결론
- **문제**: key=심볼 구조에서 파티션 증설 시 key→partition 매핑 변화로 “심볼별 순서 보장”이 깨질 수 있음
- **해결**: 파티션 증설 대신 **새 토픽(v2) 생성 후 컷오버**로 전환
- **이번 변경의 의미**: 토픽명/파티션/오프셋 모드를 **환경변수로 분리**해 코드 수정 없이 컷오버가 가능해짐