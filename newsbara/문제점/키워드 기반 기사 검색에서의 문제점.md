
# 네이버 News 검색 API에는 이미지가 없다.

1순위: 기사 링크에서 OG 이미지(og:image) 추출해서 캐싱
- 흐름
	1. 뉴스 검색 결과 받음(원문 URL 또는 네이버뉴스 URL)
	2. 백엔드에서 해당 URL을 한번 fetch
	3. HTML의 `<meta property="og:image">` 또는 `twitter:image` 파싱
	4. `thumb_url`로 저장, TTL 길게(예: 7일~30일) 캐싱
	5. 없으면 fallback

2순위 : 이미지 검색 API 를 보조로 써서 썸네일 만들기
- 예시 쿼리
	- `query = 기사제목 + 언론사명`
	- `query = 기사제목 + site:도메인`
- 기사 제목 기반으로 이미지 검색을 걸어 **대표 이미지 후보를 가져오는 방식**.
- OG 실패시 fallback으로 사용하는 것도


# 카카오 vs 카카오 나무 - 동음이의어 문제

사용자가 카카오라는 키워드를 넣었을 때 카카오(기업) vs 카카오(식물) vs 카카오(음식/초콜릿) 이라는 기준치를 준다? 

일단은 정확도 순으로 가져오면 기업쪽으로 가져옴 (이슈를 기준으로)

```bash
curl -G "https://openapi.naver.com/v1/search/news.json" \
  --data-urlencode "query=카카오" \
  --data-urlencode "display=5" \
  --data-urlencode "start=1" \
  --data-urlencode "sort=sim" \
  -H "X-Naver-Client-Id: 클라이언트 ID" \
  -H "X-Naver-Client-Secret: 클라이언트 Secret"
```

당장은 별 문제가 없을듯


## 홈 진입 시 서버가 “요청 안에서” 해야 할 일 (최소, 빠르게)

- 유저 / 키워드 로드
	1. 인증 확인
	2. DB에서 유저의 `keyword_subscription` 목록 조회
- 키워드별 “뉴스 결과 캐시” 읽기
	1. 각 키워드에 대해 캐시 키로 조회(우선 Redis 추천, 없으면 DB 캐시 테이블)
	2. 캐시가 **있고 TTL 유효**하면 그대로 사용
	3. 캐시가 **없거나 만료**면:
		- 일단 **빈 배열/이전 캐시(있다면 stale)** 로 응답에 넣고
		- “갱신이 필요하다”는 플래그만 표시(아래 비동기 잡을 트리거)
- 화면용 데이터 조립
	1. 언론사 표시: originallink의 host로 표시
	2. 썸네일
		- 캐시에 `thumb_url` 있으면 사용
		- 없으면 **placeholder**로 내려주고 끝(요청 안에서 파싱 금지)

## 홈 진입 시 서버가 “비동기로” 해야 할 일 (부담 큰 것들은 여기로)

- 키워드 캐시 갱신 잡
	- 11. 만료/미존재 키워드에 대해 “갱신 잡 enqueue”
	- (잡 내용) 네이버 뉴스 검색 API 호출 → 결과 저장/캐시 갱신
- 썸네일 채우기
	- 12. 캐시 아이템 중 `thumb_status=PENDING`인 것만 골라서
	- originallink fetch → `og:image` / `twitter:image` 파싱 → 저장
	- 실패하면 `FAIL`로 두고 TTL 지나면 재시도
	- 썸네일은 “홈 진입 순간 전부” 파싱하지 말고 **상위 N개(예: 각 키워드 top 3)** 만 우선 처리
		나머지는 사용자가 스크롤/상세 진입할 때 천천히



# 정리하자면
### A) 홈 진입(기사 리스트)

1. 서버: 유저 키워드 조회
2. 서버: `news:list:{sort}:{keyword}` Redis 조회
3. **MISS면**
    - (**락 획득 시**) 네이버 뉴스 API 호출 → 결과 저장(기사 20~50개만) → TTL 설정
    - (락 못 얻으면) **stale(있으면)** 또는 빈값/로딩값 반환
4. 응답: 기사 리스트 + `urlHash` 포함 + `thumbStatus`(있으면 OK, 없으면 PENDING)
### B) 썸네일 채우기(`/thumbs`)
1. 클라이언트: 화면에 보이는 기사들의 hash 모아서 `/thumbs?hash=...` 호출
2. 서버: `MGET thumb:{hash}` → 있는 것만 반환(OK/FAIL/PENDING)
3. **MISS인 hash들에 대해**
    - “이미 작업 중인지” 체크하고(간단히 `thumb:lock:{hash}` 같은 락)
    - 큐에 OG 파싱 작업 enqueue
4. 클라이언트: 1초 간격 3~5회 재호출(또는 SWR 재검증)  
    → 썸네일 준비된 카드만 자연스럽게 채워짐
### C) 워커(OG 파싱)
1. originallink fetch → og:image/twitter:image 추출
2. 성공:
    - DB upsert 저장(콜드)
    - Redis setex 저장(핫, TTL 짧게)
3. 실패:
    - DB에 실패 기록(선택)
    - Redis에 `FAIL` setex(짧게, 재시도 간격 관리)


## TTL 추천값(초기 운영용)
- `news:list:*`
    - sim: **30~60분**
    - date: **5~15분**
- `thumb:{hash}`(Redis 핫)
    - OK: **1~7일**(네가 RAM 걱정이면 1~3일로 시작)
    - FAIL: **1~6시간**
- DB 썸네일(콜드): `expires_at` 기준으로 **30일~90일** 같은 정책 가능
- 